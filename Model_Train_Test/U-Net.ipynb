{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b5e02fe0",
   "metadata": {},
   "source": [
    "### Unet Model Building"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe6f7fb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import colorsys\n",
    "import copy\n",
    "import time\n",
    "\n",
    "import cv2\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "\n",
    "from nets.unet import Unet as unet\n",
    "from utils.utils import cvtColor, preprocess_input, resize_image, show_config\n",
    "\n",
    "\n",
    "class Unet(object):\n",
    "    _defaults = {\n",
    "\n",
    "        \"model_path\"        : 'model_data/unet_vgg_voc.h5',\n",
    "\n",
    "        \"num_classes\"       : 3,\n",
    "\n",
    "        \"backbone\"          : \"vgg\",\n",
    "\n",
    "        \"input_shape\"       : [150, 150],\n",
    "        #-------------------------------------------------#\n",
    "        #   mix_type control the segmentation results\n",
    "        #\n",
    "        #   mix_type = 0 mixed raw image with generated results\n",
    "        #   mix_type = 1 only keep the generated result\n",
    "        #   mix_type = 2 remove the background,only keep the object\n",
    "        #-------------------------------------------------#\n",
    "        \"mix_type\"          : 0,\n",
    "    }\n",
    "\n",
    "\n",
    "    def __init__(self, **kwargs):\n",
    "        self.__dict__.update(self._defaults)\n",
    "        for name, value in kwargs.items():\n",
    "            setattr(self, name, value)\n",
    "\n",
    "        if self.num_classes <= 21:\n",
    "            self.colors = [ (0, 0, 0), (128, 0, 0), (0, 128, 0), (128, 128, 0), (0, 0, 128), (128, 0, 128), (0, 128, 128), \n",
    "                            (128, 128, 128), (64, 0, 0), (192, 0, 0), (64, 128, 0), (192, 128, 0), (64, 0, 128), (192, 0, 128), \n",
    "                            (64, 128, 128), (192, 128, 128), (0, 64, 0), (128, 64, 0), (0, 192, 0), (128, 192, 0), (0, 64, 128), \n",
    "                            (128, 64, 12)]\n",
    "        else:\n",
    "            hsv_tuples = [(x / self.num_classes, 1., 1.) for x in range(self.num_classes)]\n",
    "            self.colors = list(map(lambda x: colorsys.hsv_to_rgb(*x), hsv_tuples))\n",
    "            self.colors = list(map(lambda x: (int(x[0] * 255), int(x[1] * 255), int(x[2] * 255)), self.colors))\n",
    "\n",
    "        self.generate()\n",
    "\n",
    "        show_config(**self._defaults)\n",
    "\n",
    "\n",
    "    def generate(self):\n",
    "\n",
    "        self.model = unet([self.input_shape[0], self.input_shape[1], 3], self.num_classes, self.backbone)\n",
    "\n",
    "        self.model.load_weights(self.model_path)\n",
    "        print('{} model loaded.'.format(self.model_path))\n",
    "\n",
    "\n",
    "    def detect_image(self, image, count=False, name_classes=None):\n",
    "\n",
    "        image       = cvtColor(image)\n",
    "\n",
    "        old_img     = copy.deepcopy(image)\n",
    "        orininal_h  = np.array(image).shape[0]\n",
    "        orininal_w  = np.array(image).shape[1]\n",
    "\n",
    "        image_data, nw, nh  = resize_image(image, (self.input_shape[1], self.input_shape[0]))\n",
    "\n",
    "        image_data  = np.expand_dims(preprocess_input(np.array(image_data, np.float32)), 0)\n",
    "\n",
    "\n",
    "        pr = self.model.predict(image_data)[0]\n",
    "\n",
    "        pr = pr[int((self.input_shape[0] - nh) // 2) : int((self.input_shape[0] - nh) // 2 + nh), \\\n",
    "                int((self.input_shape[1] - nw) // 2) : int((self.input_shape[1] - nw) // 2 + nw)]\n",
    "\n",
    "        pr = cv2.resize(pr, (orininal_w, orininal_h), interpolation = cv2.INTER_LINEAR)\n",
    "\n",
    "        pr = pr.argmax(axis=-1)\n",
    "        \n",
    "\n",
    "        if count:\n",
    "            classes_nums        = np.zeros([self.num_classes])\n",
    "            total_points_num    = orininal_h * orininal_w\n",
    "            print('-' * 63)\n",
    "            print(\"|%25s | %15s | %15s|\"%(\"Key\", \"Value\", \"Ratio\"))\n",
    "            print('-' * 63)\n",
    "            for i in range(self.num_classes):\n",
    "                num     = np.sum(pr == i)\n",
    "                ratio   = num / total_points_num * 100\n",
    "                if num > 0:\n",
    "                    print(\"|%25s | %15s | %14.2f%%|\"%(str(name_classes[i]), str(num), ratio))\n",
    "                    print('-' * 63)\n",
    "                classes_nums[i] = num\n",
    "            print(\"classes_nums:\", classes_nums)\n",
    "\n",
    "        if self.mix_type == 0:\n",
    "\n",
    "            seg_img = np.reshape(np.array(self.colors, np.uint8)[np.reshape(pr, [-1])], [orininal_h, orininal_w, -1])\n",
    "\n",
    "            image   = Image.fromarray(np.uint8(seg_img))\n",
    "\n",
    "            image   = Image.blend(old_img, image, 0.7)\n",
    "\n",
    "        elif self.mix_type == 1:\n",
    "\n",
    "            seg_img = np.reshape(np.array(self.colors, np.uint8)[np.reshape(pr, [-1])], [orininal_h, orininal_w, -1])\n",
    "\n",
    "            image   = Image.fromarray(np.uint8(seg_img))\n",
    "\n",
    "        elif self.mix_type == 2:\n",
    "            seg_img = (np.expand_dims(pr != 0, -1) * np.array(old_img, np.float32)).astype('uint8')\n",
    " \n",
    "            image = Image.fromarray(np.uint8(seg_img))\n",
    "\n",
    "        return image\n",
    "\n",
    "    def get_FPS(self, image, test_interval):\n",
    "\n",
    "        image       = cvtColor(image)\n",
    "\n",
    "        image_data, nw, nh  = resize_image(image, (self.input_shape[1], self.input_shape[0]))\n",
    "\n",
    "        image_data  = np.expand_dims(preprocess_input(np.array(image_data, np.float32)), 0)\n",
    "\n",
    "\n",
    "        pr = self.model.predict(image_data)[0]\n",
    "\n",
    "        pr = pr[int((self.input_shape[0] - nh) // 2) : int((self.input_shape[0] - nh) // 2 + nh), \\\n",
    "                int((self.input_shape[1] - nw) // 2) : int((self.input_shape[1] - nw) // 2 + nw)]\n",
    "\n",
    "        pr = pr.argmax(axis=-1).reshape([self.input_shape[0],self.input_shape[1]])\n",
    "                \n",
    "        t1 = time.time()\n",
    "        for _ in range(test_interval):\n",
    "\n",
    "            pr = self.model.predict(image_data)[0]\n",
    "\n",
    "            pr = pr[int((self.input_shape[0] - nh) // 2) : int((self.input_shape[0] - nh) // 2 + nh), \\\n",
    "                    int((self.input_shape[1] - nw) // 2) : int((self.input_shape[1] - nw) // 2 + nw)]\n",
    "\n",
    "            pr = pr.argmax(axis=-1).reshape([self.input_shape[0],self.input_shape[1]])\n",
    "\n",
    "        t2 = time.time()\n",
    "        tact_time = (t2 - t1) / test_interval\n",
    "        return tact_time\n",
    "        \n",
    "    def get_miou_png(self, image):\n",
    "\n",
    "        image       = cvtColor(image)\n",
    "        orininal_h  = np.array(image).shape[0]\n",
    "        orininal_w  = np.array(image).shape[1]\n",
    "\n",
    "        image_data, nw, nh  = resize_image(image, (self.input_shape[1], self.input_shape[0]))\n",
    "\n",
    "        image_data  = np.expand_dims(preprocess_input(np.array(image_data, np.float32)), 0)\n",
    "\n",
    "        pr = self.model.predict(image_data)[0]\n",
    "\n",
    "        pr = pr[int((self.input_shape[0] - nh) // 2) : int((self.input_shape[0] - nh) // 2 + nh), \\\n",
    "                int((self.input_shape[1] - nw) // 2) : int((self.input_shape[1] - nw) // 2 + nw)]\n",
    "\n",
    "        pr = cv2.resize(pr, (orininal_w, orininal_h), interpolation = cv2.INTER_LINEAR)\n",
    "\n",
    "        pr = pr.argmax(axis=-1)\n",
    "\n",
    "        image = Image.fromarray(np.uint8(pr))\n",
    "        return image"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c518c64e",
   "metadata": {},
   "source": [
    "### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc35389d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "import os\n",
    "\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from keras.callbacks import (EarlyStopping, LearningRateScheduler,\n",
    "                             ModelCheckpoint, TensorBoard)\n",
    "from keras.layers import Conv2D, Dense, DepthwiseConv2D\n",
    "from keras.optimizers import SGD, Adam\n",
    "from keras.regularizers import l2\n",
    "from keras.utils.multi_gpu_utils import multi_gpu_model\n",
    "\n",
    "from nets.unet import Unet\n",
    "from nets.unet_training import (CE, Focal_Loss, dice_loss_with_CE,\n",
    "                                dice_loss_with_Focal_Loss, get_lr_scheduler)\n",
    "from utils.callbacks import EvalCallback, LossHistory, ParallelModelCheckpoint\n",
    "from utils.dataloader import UnetDataset\n",
    "from utils.utils import show_config\n",
    "from utils.utils_metrics import Iou_score, f_score\n",
    "\n",
    "tf.logging.set_verbosity(tf.logging.ERROR)\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":    \n",
    "\n",
    "    train_gpu   = [0,]\n",
    "\n",
    "    num_classes     = 3\n",
    "\n",
    "    backbone        = \"vgg\"\n",
    "\n",
    "    model_path      = \"model_data/unet_vgg_voc.h5\"\n",
    "\n",
    "    input_shape     = [150, 150]\n",
    "\n",
    "\n",
    "    Init_Epoch          = 0\n",
    "    Freeze_Epoch        = 50\n",
    "    Freeze_batch_size   = 2\n",
    " \n",
    "    UnFreeze_Epoch      = 100\n",
    "    Unfreeze_batch_size = 2\n",
    "\n",
    "    Freeze_Train        = True\n",
    "\n",
    "\n",
    "    Init_lr             = 1e-4\n",
    "    Min_lr              = Init_lr * 0.01\n",
    "\n",
    "    optimizer_type      = \"adam\"\n",
    "    momentum            = 0.9\n",
    "    weight_decay        = 0\n",
    "\n",
    "    lr_decay_type       = 'cos'\n",
    "\n",
    "    save_period         = 5\n",
    "\n",
    "    save_dir            = 'logs'\n",
    "\n",
    "    eval_flag           = True\n",
    "    eval_period         = 5\n",
    "    \n",
    "\n",
    "    VOCdevkit_path  = 'VOCdevkit'\n",
    "\n",
    "    dice_loss       = False\n",
    "\n",
    "    focal_loss      = False\n",
    "\n",
    "    cls_weights     = np.ones([num_classes], np.float32)\n",
    "\n",
    "    num_workers     = 1\n",
    "\n",
    "\n",
    "    os.environ[\"CUDA_VISIBLE_DEVICES\"]  = ','.join(str(x) for x in train_gpu)\n",
    "    ngpus_per_node                      = len(train_gpu)\n",
    "    print('Number of devices: {}'.format(ngpus_per_node))\n",
    "\n",
    "    model_body = Unet([input_shape[0], input_shape[1], 3], num_classes, backbone)\n",
    "    if model_path != '':\n",
    " \n",
    "        model_body.load_weights(model_path, by_name=True, skip_mismatch=True)\n",
    "\n",
    "    if ngpus_per_node > 1:\n",
    "        model = multi_gpu_model(model_body, gpus=ngpus_per_node)\n",
    "    else:\n",
    "        model = model_body\n",
    "\n",
    "\n",
    "    if focal_loss:\n",
    "        if dice_loss:\n",
    "            loss = dice_loss_with_Focal_Loss(cls_weights)\n",
    "        else:\n",
    "            loss = Focal_Loss(cls_weights)\n",
    "    else:\n",
    "        if dice_loss:\n",
    "            loss = dice_loss_with_CE(cls_weights)\n",
    "        else:\n",
    "            loss = CE(cls_weights)\n",
    "\n",
    "\n",
    "    with open(os.path.join(VOCdevkit_path, \"VOC2007/ImageSets/Segmentation/train.txt\"),\"r\") as f:\n",
    "        train_lines = f.readlines()\n",
    "    with open(os.path.join(VOCdevkit_path, \"VOC2007/ImageSets/Segmentation/val.txt\"),\"r\") as f:\n",
    "        val_lines = f.readlines()\n",
    "    num_train   = len(train_lines)\n",
    "    num_val     = len(val_lines)\n",
    "\n",
    "    show_config(\n",
    "        num_classes = num_classes, backbone = backbone, model_path = model_path, input_shape = input_shape, \\\n",
    "        Init_Epoch = Init_Epoch, Freeze_Epoch = Freeze_Epoch, UnFreeze_Epoch = UnFreeze_Epoch, Freeze_batch_size = Freeze_batch_size, Unfreeze_batch_size = Unfreeze_batch_size, Freeze_Train = Freeze_Train, \\\n",
    "        Init_lr = Init_lr, Min_lr = Min_lr, optimizer_type = optimizer_type, momentum = momentum, lr_decay_type = lr_decay_type, \\\n",
    "        save_period = save_period, save_dir = save_dir, num_workers = num_workers, num_train = num_train, num_val = num_val\n",
    "    )\n",
    "\n",
    "    for layer in model.layers:\n",
    "        if isinstance(layer, DepthwiseConv2D):\n",
    "                layer.add_loss(l2(weight_decay)(layer.depthwise_kernel))\n",
    "        elif isinstance(layer, Conv2D) or isinstance(layer, Dense):\n",
    "                layer.add_loss(l2(weight_decay)(layer.kernel))\n",
    "                \n",
    "\n",
    "    if True:\n",
    "\n",
    "            if backbone == \"vgg\":\n",
    "                freeze_layers = 17\n",
    "            elif backbone == \"resnet50\":\n",
    "                freeze_layers = 172\n",
    "            else:\n",
    "                raise ValueError('Unsupported backbone - `{}`, Use vgg, resnet50.'.format(backbone))\n",
    "            for i in range(freeze_layers): model_body.layers[i].trainable = False\n",
    "            print('Freeze the first {} layers of total {} layers.'.format(freeze_layers, len(model_body.layers)))\n",
    "\n",
    "\n",
    "        batch_size  = Freeze_batch_size if Freeze_Train else Unfreeze_batch_size\n",
    "        start_epoch = Init_Epoch\n",
    "        end_epoch   = Freeze_Epoch if Freeze_Train else UnFreeze_Epoch\n",
    "        \n",
    "\n",
    "        nbs             = 16\n",
    "        lr_limit_max    = 1e-4 if optimizer_type == 'adam' else 1e-1\n",
    "        lr_limit_min    = 1e-4 if optimizer_type == 'adam' else 5e-4\n",
    "        Init_lr_fit     = min(max(batch_size / nbs * Init_lr, lr_limit_min), lr_limit_max)\n",
    "        Min_lr_fit      = min(max(batch_size / nbs * Min_lr, lr_limit_min * 1e-2), lr_limit_max * 1e-2)\n",
    "\n",
    "        optimizer = {\n",
    "            'adam'  : Adam(lr = Init_lr_fit, beta_1 = momentum),\n",
    "            'sgd'   : SGD(lr = Init_lr_fit, momentum = momentum, nesterov=True)\n",
    "        }[optimizer_type]\n",
    "        model.compile(loss = loss,\n",
    "                optimizer = optimizer,\n",
    "                metrics = [f_score()])\n",
    "\n",
    "        lr_scheduler_func = get_lr_scheduler(lr_decay_type, Init_lr_fit, Min_lr_fit, UnFreeze_Epoch)\n",
    "\n",
    "        epoch_step          = num_train // batch_size\n",
    "        epoch_step_val      = num_val // batch_size\n",
    "\n",
    "        if epoch_step == 0 or epoch_step_val == 0:\n",
    "            raise ValueError('Training set is too small!')\n",
    "\n",
    "        train_dataloader    = UnetDataset(train_lines, input_shape, batch_size, num_classes, True, VOCdevkit_path)\n",
    "        val_dataloader      = UnetDataset(val_lines, input_shape, batch_size, num_classes, False, VOCdevkit_path)\n",
    "\n",
    "\n",
    "        time_str        = datetime.datetime.strftime(datetime.datetime.now(),'%Y_%m_%d_%H_%M_%S')\n",
    "        log_dir         = os.path.join(save_dir, \"loss_\" + str(time_str))\n",
    "        logging         = TensorBoard(log_dir)\n",
    "        loss_history    = LossHistory(log_dir)\n",
    "        if ngpus_per_node > 1:\n",
    "            checkpoint      = ParallelModelCheckpoint(model_body, os.path.join(save_dir, \"ep{epoch:03d}-loss{loss:.3f}-val_loss{val_loss:.3f}.h5\"), \n",
    "                                    monitor = 'val_loss', save_weights_only = True, save_best_only = False, period = save_period)\n",
    "            checkpoint_last = ParallelModelCheckpoint(model_body, os.path.join(save_dir, \"last_epoch_weights.h5\"), \n",
    "                                    monitor = 'val_loss', save_weights_only = True, save_best_only = False, period = 1)\n",
    "            checkpoint_best = ParallelModelCheckpoint(model_body, os.path.join(save_dir, \"best_epoch_weights.h5\"), \n",
    "                                    monitor = 'val_loss', save_weights_only = True, save_best_only = True, period = 1)\n",
    "        else:\n",
    "            checkpoint      = ModelCheckpoint(os.path.join(save_dir, \"ep{epoch:03d}-loss{loss:.3f}-val_loss{val_loss:.3f}.h5\"), \n",
    "                                    monitor = 'val_loss', save_weights_only = True, save_best_only = False, period = save_period)\n",
    "            checkpoint_last = ModelCheckpoint(os.path.join(save_dir, \"last_epoch_weights.h5\"), \n",
    "                                    monitor = 'val_loss', save_weights_only = True, save_best_only = False, period = 1)\n",
    "            checkpoint_best = ModelCheckpoint(os.path.join(save_dir, \"best_epoch_weights.h5\"), \n",
    "                                    monitor = 'val_loss', save_weights_only = True, save_best_only = True, period = 1)\n",
    "        early_stopping  = EarlyStopping(monitor='val_loss', min_delta = 0, patience = 10, verbose = 1)\n",
    "        lr_scheduler    = LearningRateScheduler(lr_scheduler_func, verbose = 1)\n",
    "        eval_callback   = EvalCallback(model_body, input_shape, num_classes, val_lines, VOCdevkit_path, log_dir, \\\n",
    "                                        eval_flag=eval_flag, period=eval_period)\n",
    "        callbacks       = [logging, loss_history, checkpoint, checkpoint_last, checkpoint_best, lr_scheduler, eval_callback]\n",
    "\n",
    "        if start_epoch < end_epoch:\n",
    "            print('Train on {} samples, val on {} samples, with batch size {}.'.format(num_train, num_val, batch_size))\n",
    "            model.fit_generator(\n",
    "                generator           = train_dataloader,\n",
    "                steps_per_epoch     = epoch_step,\n",
    "                validation_data     = val_dataloader,\n",
    "                validation_steps    = epoch_step_val,\n",
    "                epochs              = end_epoch,\n",
    "                initial_epoch       = start_epoch,\n",
    "                use_multiprocessing = True if num_workers > 1 else False,\n",
    "                workers             = num_workers,\n",
    "                callbacks           = callbacks\n",
    "            )\n",
    "\n",
    "        if Freeze_Train:\n",
    "            batch_size  = Unfreeze_batch_size\n",
    "            start_epoch = Freeze_Epoch if start_epoch < Freeze_Epoch else start_epoch\n",
    "            end_epoch   = UnFreeze_Epoch\n",
    "                \n",
    "\n",
    "            nbs             = 16\n",
    "            lr_limit_max    = 1e-4 if optimizer_type == 'adam' else 1e-1\n",
    "            lr_limit_min    = 1e-4 if optimizer_type == 'adam' else 5e-4\n",
    "            Init_lr_fit     = min(max(batch_size / nbs * Init_lr, lr_limit_min), lr_limit_max)\n",
    "            Min_lr_fit      = min(max(batch_size / nbs * Min_lr, lr_limit_min * 1e-2), lr_limit_max * 1e-2)\n",
    "\n",
    "            lr_scheduler_func = get_lr_scheduler(lr_decay_type, Init_lr_fit, Min_lr_fit, UnFreeze_Epoch)\n",
    "            lr_scheduler    = LearningRateScheduler(lr_scheduler_func, verbose = 1)\n",
    "            callbacks       = [logging, loss_history, checkpoint, checkpoint_last, checkpoint_best, lr_scheduler, eval_callback]\n",
    "            \n",
    "            for i in range(len(model_body.layers)): \n",
    "                model_body.layers[i].trainable = True\n",
    "            model.compile(loss = loss,\n",
    "                    optimizer = optimizer,\n",
    "                    metrics = [f_score()])\n",
    "\n",
    "            epoch_step      = num_train // batch_size\n",
    "            epoch_step_val  = num_val // batch_size\n",
    "\n",
    "            if epoch_step == 0 or epoch_step_val == 0:\n",
    "                raise ValueError(\"Training set is too samll!\")\n",
    "\n",
    "            train_dataloader.batch_size    = Unfreeze_batch_size\n",
    "            val_dataloader.batch_size      = Unfreeze_batch_size\n",
    "\n",
    "            print('Train on {} samples, val on {} samples, with batch size {}.'.format(num_train, num_val, batch_size))\n",
    "            model.fit_generator(\n",
    "                generator           = train_dataloader,\n",
    "                steps_per_epoch     = epoch_step,\n",
    "                validation_data     = val_dataloader,\n",
    "                validation_steps    = epoch_step_val,\n",
    "                epochs              = end_epoch,\n",
    "                initial_epoch       = start_epoch,\n",
    "                use_multiprocessing = True if num_workers > 1 else False,\n",
    "                workers             = num_workers,\n",
    "                callbacks           = callbacks\n",
    "            )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9dc910a",
   "metadata": {},
   "source": [
    "### Predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3dc507ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "import cv2\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "from unet import Unet\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "  \n",
    "    unet = Unet()\n",
    "    \n",
    "    dir_origin_path = \"img/\"\n",
    "    dir_save_path   = \"img_out/\"\n",
    "\n",
    " \n",
    "\n",
    "\n",
    "\n",
    "    img_names = os.listdir(dir_origin_path)\n",
    "    for img_name in tqdm(img_names):\n",
    "        if img_name.lower().endswith(('.bmp', '.dib', '.png', '.jpg', '.jpeg', '.pbm', '.pgm', '.ppm', '.tif', '.tiff')):\n",
    "            image_path  = os.path.join(dir_origin_path, img_name)\n",
    "            image       = Image.open(image_path)\n",
    "            r_image     = unet.detect_image(image)\n",
    "            if not os.path.exists(dir_save_path):\n",
    "                os.makedirs(dir_save_path)\n",
    "            r_image.save(os.path.join(dir_save_path, img_name))\n",
    "                \n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
